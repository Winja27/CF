{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.linalg import svd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据并进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(path:str):\n",
    "    \"\"\"\n",
    "    读取数据并进行预处理\n",
    "    :param path: 数据路径\n",
    "    :return: 数据矩阵，行索引，列索引\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path, index_col=0)\n",
    "    return data.values, data.index, data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 5. , 5. , 4.5, 5. , 5. , 4.5, 4.5, 4.5, 4.5],\n",
       "       [4.5, 5. , 4. , 4.5, 4.5, 4. , 3.5, 4.5, 4.5, 4.5],\n",
       "       [4. , 3.5, 4.5, 2.5, 4. , 4. , 2.5, 3.5, 4.5, 3. ],\n",
       "       [3.5, 3.5, 3. , 4. , 4. , 4. , 3.5, 4. , 3.5, 3.5],\n",
       "       [4.5, 4.5, 5. , 4. , 4. , 3. , 3.5, 4.5, 4.5, 4. ],\n",
       "       [5. , 5. , 5. , 5. , 3. , 5. , 2. , 5. , 4. , 5. ],\n",
       "       [5. , 4. , 5. , 4. , 4. , 5. , 4. , 5. , 5. , 5. ],\n",
       "       [5. , 5. , 5. , 3. , 5. , 5. , 2. , 5. , 4. , 5. ],\n",
       "       [5. , 5. , 5. , 4. , 5. , 5. , 4. , 5. , 5. , 4. ],\n",
       "       [5. , 5. , 4. , 4. , 3.5, 3. , 3.5, 4. , 3.5, 4. ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw, _, _ = data_preprocess('svd-raw-data.csv')\n",
    "data_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分验证集和训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spilt_train_valid(data:np.ndarray):\n",
    "    \"\"\"\n",
    "    将数据集划分为训练集和验证集\n",
    "    :param data: 数据集\n",
    "    :return: 训练集，验证集，训练集索引，验证集索引\n",
    "    \"\"\"\n",
    "    row, col = data.shape\n",
    "    indices = indices = [(i,j) for i in range(row) for j in range(col)]\n",
    "    random.seed(100)\n",
    "    # 随机取三十个索引作为验证集\n",
    "    random_list = random.sample(range(0, len(indices)), int(len(indices)*0.3))\n",
    "\n",
    "    valid_indices = [indices[i] for i in random_list]   \n",
    "    train_indices = list(set(indices) - set(valid_indices)) \n",
    "    valid_indices = np.array(valid_indices).T[0], np.array(valid_indices).T[1]  # 验证集索引\n",
    "    train_indices = np.array(train_indices).T[0], np.array(train_indices).T[1]  # 训练集索引\n",
    "    train = data.copy()\n",
    "    train[valid_indices] = 0    # 训练集\n",
    "    valid = data.copy()\n",
    "    valid[train_indices] = 0    # 验证集\n",
    "    return train, valid, train_indices, valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5. , 5. , 5. , 4.5, 5. , 5. , 0. , 4.5, 4.5, 4.5],\n",
       "        [0. , 5. , 4. , 4.5, 0. , 0. , 3.5, 4.5, 0. , 4.5],\n",
       "        [4. , 3.5, 0. , 2.5, 0. , 4. , 0. , 3.5, 4.5, 0. ],\n",
       "        [3.5, 3.5, 3. , 0. , 4. , 4. , 3.5, 4. , 3.5, 0. ],\n",
       "        [4.5, 4.5, 0. , 4. , 0. , 3. , 3.5, 0. , 4.5, 4. ],\n",
       "        [0. , 5. , 0. , 5. , 3. , 0. , 2. , 5. , 0. , 5. ],\n",
       "        [5. , 4. , 5. , 4. , 0. , 5. , 4. , 5. , 0. , 5. ],\n",
       "        [5. , 5. , 5. , 3. , 5. , 5. , 2. , 0. , 4. , 5. ],\n",
       "        [5. , 0. , 0. , 4. , 5. , 5. , 4. , 5. , 5. , 4. ],\n",
       "        [0. , 5. , 0. , 0. , 3.5, 3. , 0. , 0. , 0. , 0. ]]),\n",
       " array([[0. , 0. , 0. , 0. , 0. , 0. , 4.5, 0. , 0. , 0. ],\n",
       "        [4.5, 0. , 0. , 0. , 4.5, 4. , 0. , 0. , 4.5, 0. ],\n",
       "        [0. , 0. , 4.5, 0. , 4. , 0. , 2.5, 0. , 0. , 3. ],\n",
       "        [0. , 0. , 0. , 4. , 0. , 0. , 0. , 0. , 0. , 3.5],\n",
       "        [0. , 0. , 5. , 0. , 4. , 0. , 0. , 4.5, 0. , 0. ],\n",
       "        [5. , 0. , 5. , 0. , 0. , 5. , 0. , 0. , 4. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 4. , 0. , 0. , 0. , 5. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. , 5. , 0. , 0. ],\n",
       "        [0. , 5. , 5. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [5. , 0. , 4. , 4. , 0. , 0. , 3.5, 4. , 3.5, 4. ]]),\n",
       " (array([4, 3, 4, 4, 3, 3, 5, 4, 5, 8, 5, 9, 0, 8, 8, 0, 8, 1, 0, 2, 1, 1,\n",
       "         2, 7, 6, 7, 6, 3, 4, 5, 4, 3, 5, 5, 9, 8, 9, 0, 0, 8, 1, 0, 2, 2,\n",
       "         6, 7, 7, 7, 6, 7, 3, 4, 3, 3, 8, 0, 8, 1, 0, 0, 2, 2, 1, 7, 6, 6,\n",
       "         7, 6, 6, 7]),\n",
       "  array([0, 4, 3, 9, 1, 7, 4, 6, 1, 0, 7, 5, 2, 9, 3, 5, 6, 6, 8, 5, 3, 9,\n",
       "         8, 4, 2, 1, 5, 0, 5, 6, 8, 6, 3, 9, 1, 5, 4, 1, 7, 8, 2, 4, 1, 7,\n",
       "         1, 0, 3, 9, 7, 6, 2, 1, 5, 8, 4, 0, 7, 1, 3, 9, 0, 3, 7, 2, 0, 6,\n",
       "         5, 3, 9, 8])),\n",
       " (array([1, 5, 9, 2, 9, 5, 9, 4, 5, 6, 1, 6, 1, 1, 9, 3, 0, 8, 2, 4, 2, 3,\n",
       "         8, 9, 9, 2, 9, 4, 5, 7]),\n",
       "  array([8, 8, 8, 2, 0, 0, 3, 4, 5, 4, 4, 8, 5, 0, 7, 3, 6, 2, 6, 2, 9, 9,\n",
       "         1, 6, 9, 4, 2, 7, 2, 7])))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix, valid_matrix, train_indices, valid_indices = spilt_train_valid(data_raw)\n",
    "train_matrix, valid_matrix, train_indices, valid_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将平均值填入训练集的空值部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train_matrix:np.ndarray)->np.ndarray:\n",
    "    \"\"\"\n",
    "    对训练集中的空值进行处理，填入用户评分均值\n",
    "    :param train_matrix: 训练集\n",
    "    :return: 处理后的训练集\n",
    "    \"\"\"\n",
    "    row, col = train_matrix.shape\n",
    "    mean = np.sum(train_matrix, axis=1) / np.sum(train_matrix != 0, axis=1)\n",
    "    mean = mean.reshape(row, 1)\n",
    "    # 将空值替换为该行的平均值\n",
    "    train_matrix = np.where(train_matrix == 0, mean, train_matrix)\n",
    "    return train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.        , 5.        , 5.        , 4.5       , 5.        ,\n",
       "        5.        , 4.77777778, 4.5       , 4.5       , 4.5       ],\n",
       "       [4.33333333, 5.        , 4.        , 4.5       , 4.33333333,\n",
       "        4.33333333, 3.5       , 4.5       , 4.33333333, 4.5       ],\n",
       "       [4.        , 3.5       , 3.66666667, 2.5       , 3.66666667,\n",
       "        4.        , 3.66666667, 3.5       , 4.5       , 3.66666667],\n",
       "       [3.5       , 3.5       , 3.        , 3.625     , 4.        ,\n",
       "        4.        , 3.5       , 4.        , 3.5       , 3.625     ],\n",
       "       [4.5       , 4.5       , 4.        , 4.        , 4.        ,\n",
       "        3.        , 3.5       , 4.        , 4.5       , 4.        ],\n",
       "       [4.16666667, 5.        , 4.16666667, 5.        , 3.        ,\n",
       "        4.16666667, 2.        , 5.        , 4.16666667, 5.        ],\n",
       "       [5.        , 4.        , 5.        , 4.        , 4.625     ,\n",
       "        5.        , 4.        , 5.        , 4.625     , 5.        ],\n",
       "       [5.        , 5.        , 5.        , 3.        , 5.        ,\n",
       "        5.        , 2.        , 4.33333333, 4.        , 5.        ],\n",
       "       [5.        , 4.625     , 4.625     , 4.        , 5.        ,\n",
       "        5.        , 4.        , 5.        , 5.        , 4.        ],\n",
       "       [3.83333333, 5.        , 3.83333333, 3.83333333, 3.5       ,\n",
       "        3.        , 3.83333333, 3.83333333, 3.83333333, 3.83333333]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix= normalize(train_matrix)\n",
    "train_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD分解，保留部分特征值并还原"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVD(train_mat:np.ndarray, k:int)->np.ndarray:\n",
    "    \"\"\"\n",
    "    使用SVD对训练集进行分解，保留部分特征值，并预测\n",
    "    :param train_mat: 训练集\n",
    "    :param k: 保留的特征值数量\n",
    "    :return: 还原后的矩阵\n",
    "    \"\"\"\n",
    "    U, sigma, VT = svd(train_mat)\n",
    "    sigma = np.diag(sigma[:k])  # 保留前k个特征值\n",
    "    predict_mat = U[:, :k].dot(sigma).dot(VT[:k, :]) # 还原矩阵\n",
    "    return predict_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.03361431, 4.88473341, 4.72651527, 4.27623309, 4.97959336,\n",
       "        4.7890814 , 4.65812553, 4.80548685, 4.99669462, 4.57918187],\n",
       "       [4.47972269, 4.87503946, 4.28097577, 4.39910078, 4.09928666,\n",
       "        4.15384148, 3.53427544, 4.59258754, 4.40803829, 4.5052753 ],\n",
       "       [3.99157775, 3.47688965, 3.75164219, 2.82799861, 4.13870444,\n",
       "        3.97635572, 3.65057575, 3.58737015, 3.85943136, 3.44163675],\n",
       "       [3.79774139, 3.76749788, 3.57090481, 3.33182174, 3.71204889,\n",
       "        3.58541856, 3.47614115, 3.67316151, 3.77876082, 3.50667183],\n",
       "       [4.08774952, 4.46508538, 3.8499377 , 4.14831594, 3.7891127 ,\n",
       "        3.69096868, 3.70150714, 4.18680173, 4.15135554, 3.99289732],\n",
       "       [4.23128926, 5.35556128, 4.20806647, 4.88460831, 3.34053089,\n",
       "        3.86487889, 1.9760549 , 4.80107491, 3.97892051, 4.99799526],\n",
       "       [5.00201569, 4.68732632, 4.78843152, 3.83583328, 4.937859  ,\n",
       "        4.98121336, 3.85131606, 4.70270078, 4.72256592, 4.672486  ],\n",
       "       [4.92774638, 4.50133688, 4.92856877, 3.20096066, 4.7095041 ,\n",
       "        5.30286329, 2.00953995, 4.61694896, 4.15672332, 5.01822726],\n",
       "       [4.97247565, 4.65700713, 4.71537881, 3.89740014, 4.95488736,\n",
       "        4.87984103, 4.20594456, 4.66287094, 4.79321554, 4.54329593],\n",
       "       [3.8261347 , 4.40271532, 3.57450496, 4.25296673, 3.46670986,\n",
       "        3.30999361, 3.71672459, 4.03824517, 4.00344825, 3.78362337]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_matrix = SVD(train_matrix, k=3)\n",
    "predict_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE & RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(valid_mat, predict_mat, valid_indices):\n",
    "    temp = valid_mat[valid_indices] - predict_mat[valid_indices]\n",
    "    return np.mean(np.abs(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(valid_mat, predict_mat, valid_indices):\n",
    "    temp = valid_mat[valid_indices] - predict_mat[valid_indices]\n",
    "    return np.sqrt(np.mean(temp ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21235349144597607, 0.2794083444700769)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE(train_matrix, predict_matrix, train_indices), RMSE(train_matrix, predict_matrix, train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19414459329313868, 0.2508810377113763)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict_matrix[train_indices] = train_matrix[train_indices]\n",
    "# predict_matrix = SVD(predict_matrix, k=3)\n",
    "# MAE(train_matrix, predict_matrix, train_indices), RMSE(train_matrix, predict_matrix, train_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_matrix:np.ndarray, train_indices, k:int, epoch:int=200, log:bool=True)->tuple[np.ndarray, float, float]:\n",
    "    \"\"\"\n",
    "    训练\n",
    "    :params train_matrix: 训练集\n",
    "    :params train_indices: 训练集索引\n",
    "    :params k: 保留的特征值数量\n",
    "    :params epoch: 迭代次数\n",
    "    :params log: 是否打印日志\n",
    "    :return 预测矩阵\n",
    "    \"\"\"\n",
    "    train_matrix_ori = train_matrix.copy()\n",
    "    for i in range(epoch):\n",
    "        train_matrix = SVD(train_mat=train_matrix, k=k)\n",
    "        if log:\n",
    "            print(f\"epoch: {i+1}\\tMAE: {MAE(train_matrix_ori, train_matrix, train_indices)}\")\n",
    "        train_matrix[train_indices] = train_matrix_ori[train_indices]        \n",
    "    return train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\tMAE: 0.21235349144597607\n",
      "epoch: 2\tMAE: 0.19414459329313868\n",
      "epoch: 3\tMAE: 0.18415855915897764\n",
      "epoch: 4\tMAE: 0.17840898452339005\n",
      "epoch: 5\tMAE: 0.17482802361369537\n",
      "epoch: 6\tMAE: 0.1722039207680848\n",
      "epoch: 7\tMAE: 0.1698983411605974\n",
      "epoch: 8\tMAE: 0.16782354364283003\n",
      "epoch: 9\tMAE: 0.16608963494831241\n",
      "epoch: 10\tMAE: 0.16457445107775695\n",
      "epoch: 11\tMAE: 0.1632955118402983\n",
      "epoch: 12\tMAE: 0.16225733964225345\n",
      "epoch: 13\tMAE: 0.16135774372199943\n",
      "epoch: 14\tMAE: 0.1605325795574629\n",
      "epoch: 15\tMAE: 0.159775344660985\n",
      "epoch: 16\tMAE: 0.15907947062840405\n",
      "epoch: 17\tMAE: 0.15843849454106648\n",
      "epoch: 18\tMAE: 0.15784614250873247\n",
      "epoch: 19\tMAE: 0.15729637834898\n",
      "epoch: 20\tMAE: 0.1567834394047729\n",
      "epoch: 21\tMAE: 0.15630186807906438\n",
      "epoch: 22\tMAE: 0.1558465422793059\n",
      "epoch: 23\tMAE: 0.15541270586574293\n",
      "epoch: 24\tMAE: 0.15499599923952867\n",
      "epoch: 25\tMAE: 0.15459248953538962\n",
      "epoch: 26\tMAE: 0.15419869924196464\n",
      "epoch: 27\tMAE: 0.15381163146091145\n",
      "epoch: 28\tMAE: 0.15342878953021744\n",
      "epoch: 29\tMAE: 0.1530481884937706\n",
      "epoch: 30\tMAE: 0.15266835599106565\n",
      "epoch: 31\tMAE: 0.15233791386785317\n",
      "epoch: 32\tMAE: 0.15204284606041152\n",
      "epoch: 33\tMAE: 0.15174736179535875\n",
      "epoch: 34\tMAE: 0.15153339498012192\n",
      "epoch: 35\tMAE: 0.15135810369608751\n",
      "epoch: 36\tMAE: 0.15119828673678573\n",
      "epoch: 37\tMAE: 0.1510373200985102\n",
      "epoch: 38\tMAE: 0.1508947898726488\n",
      "epoch: 39\tMAE: 0.1507482112431382\n",
      "epoch: 40\tMAE: 0.1505979860103304\n",
      "epoch: 41\tMAE: 0.15044477146910284\n",
      "epoch: 42\tMAE: 0.15031331495277836\n",
      "epoch: 43\tMAE: 0.1501786609402597\n",
      "epoch: 44\tMAE: 0.15004153028805833\n",
      "epoch: 45\tMAE: 0.14990264254068478\n",
      "epoch: 46\tMAE: 0.14976269425782465\n",
      "epoch: 47\tMAE: 0.14962234247926876\n",
      "epoch: 48\tMAE: 0.14948219293125106\n",
      "epoch: 49\tMAE: 0.14934279241882129\n",
      "epoch: 50\tMAE: 0.14920462476636548\n",
      "epoch: 51\tMAE: 0.1490681096478295\n",
      "epoch: 52\tMAE: 0.1489336036734762\n",
      "epoch: 53\tMAE: 0.14880140315578902\n",
      "epoch: 54\tMAE: 0.1486717480503174\n",
      "epoch: 55\tMAE: 0.14854482664751378\n",
      "epoch: 56\tMAE: 0.1484207806714944\n",
      "epoch: 57\tMAE: 0.14829971051619298\n",
      "epoch: 58\tMAE: 0.14818168041571872\n",
      "epoch: 59\tMAE: 0.14806672340253213\n",
      "epoch: 60\tMAE: 0.14795484595414432\n",
      "epoch: 61\tMAE: 0.1478460322668764\n",
      "epoch: 62\tMAE: 0.14774087205708453\n",
      "epoch: 63\tMAE: 0.1476434230284803\n",
      "epoch: 64\tMAE: 0.1475484572531609\n",
      "epoch: 65\tMAE: 0.14745593212541364\n",
      "epoch: 66\tMAE: 0.14736579733624922\n",
      "epoch: 67\tMAE: 0.14727799668072034\n",
      "epoch: 68\tMAE: 0.14719246959432272\n",
      "epoch: 69\tMAE: 0.14710915244858194\n",
      "epoch: 70\tMAE: 0.1470279796345866\n",
      "epoch: 71\tMAE: 0.14694888446131704\n",
      "epoch: 72\tMAE: 0.14687179989343002\n",
      "epoch: 73\tMAE: 0.14679665915081916\n",
      "epoch: 74\tMAE: 0.14672339618993382\n",
      "epoch: 75\tMAE: 0.14665194608456958\n",
      "epoch: 76\tMAE: 0.14658224532169675\n",
      "epoch: 77\tMAE: 0.1465142320259228\n",
      "epoch: 78\tMAE: 0.14644784612437067\n",
      "epoch: 79\tMAE: 0.1463830294621282\n",
      "epoch: 80\tMAE: 0.14632198377392697\n",
      "epoch: 81\tMAE: 0.14627301681625202\n",
      "epoch: 82\tMAE: 0.1462251818964359\n",
      "epoch: 83\tMAE: 0.14617843932259633\n",
      "epoch: 84\tMAE: 0.14613275074960033\n",
      "epoch: 85\tMAE: 0.14608807920716685\n",
      "epoch: 86\tMAE: 0.14604438910972145\n",
      "epoch: 87\tMAE: 0.14600164625162818\n",
      "epoch: 88\tMAE: 0.1459598177908565\n",
      "epoch: 89\tMAE: 0.14591887222363104\n",
      "epoch: 90\tMAE: 0.14587877935218566\n",
      "epoch: 91\tMAE: 0.14583951024737493\n",
      "epoch: 92\tMAE: 0.14580103720758486\n",
      "epoch: 93\tMAE: 0.14576333371512687\n",
      "epoch: 94\tMAE: 0.1457263743910727\n",
      "epoch: 95\tMAE: 0.14569013494930655\n",
      "epoch: 96\tMAE: 0.14565459215041973\n",
      "epoch: 97\tMAE: 0.14561972375593246\n",
      "epoch: 98\tMAE: 0.1455855084832355\n",
      "epoch: 99\tMAE: 0.14555192596153765\n",
      "epoch: 100\tMAE: 0.14551895668905312\n",
      "epoch: 101\tMAE: 0.14548658199157855\n",
      "epoch: 102\tMAE: 0.14545478398258285\n",
      "epoch: 103\tMAE: 0.1454235455248749\n",
      "epoch: 104\tMAE: 0.145392850193896\n",
      "epoch: 105\tMAE: 0.1453626822426468\n",
      "epoch: 106\tMAE: 0.1453330265682466\n",
      "epoch: 107\tMAE: 0.14530386868010098\n",
      "epoch: 108\tMAE: 0.14527519466964642\n",
      "epoch: 109\tMAE: 0.14524699118162396\n",
      "epoch: 110\tMAE: 0.1452192453868378\n",
      "epoch: 111\tMAE: 0.14519194495634022\n",
      "epoch: 112\tMAE: 0.14516507803698334\n",
      "epoch: 113\tMAE: 0.14513863322828177\n",
      "epoch: 114\tMAE: 0.14511259956052192\n",
      "epoch: 115\tMAE: 0.14508696647406039\n",
      "epoch: 116\tMAE: 0.14506172379974766\n",
      "epoch: 117\tMAE: 0.14503686174042132\n",
      "epoch: 118\tMAE: 0.14501237085341073\n",
      "epoch: 119\tMAE: 0.14498824203399857\n",
      "epoch: 120\tMAE: 0.14496446649978278\n",
      "epoch: 121\tMAE: 0.14494103577589343\n",
      "epoch: 122\tMAE: 0.14491794168101052\n",
      "epoch: 123\tMAE: 0.14489517631414003\n",
      "epoch: 124\tMAE: 0.14487273204210319\n",
      "epoch: 125\tMAE: 0.1448506014876947\n",
      "epoch: 126\tMAE: 0.14482877751847628\n",
      "epoch: 127\tMAE: 0.1448072532361594\n",
      "epoch: 128\tMAE: 0.14478602196655435\n",
      "epoch: 129\tMAE: 0.14476507725003926\n",
      "epoch: 130\tMAE: 0.14474441283252817\n",
      "epoch: 131\tMAE: 0.1447240226569037\n",
      "epoch: 132\tMAE: 0.1447039008548881\n",
      "epoch: 133\tMAE: 0.1446840417393272\n",
      "epoch: 134\tMAE: 0.14466443979686347\n",
      "epoch: 135\tMAE: 0.14464508968097475\n",
      "epoch: 136\tMAE: 0.14462598620535622\n",
      "epoch: 137\tMAE: 0.14460712433762746\n",
      "epoch: 138\tMAE: 0.14458849919334937\n",
      "epoch: 139\tMAE: 0.14457010603032217\n",
      "epoch: 140\tMAE: 0.14455194024316112\n",
      "epoch: 141\tMAE: 0.14453399735812864\n",
      "epoch: 142\tMAE: 0.14451627302820488\n",
      "epoch: 143\tMAE: 0.1444987630283901\n",
      "epoch: 144\tMAE: 0.14448146325122477\n",
      "epoch: 145\tMAE: 0.1444643697025081\n",
      "epoch: 146\tMAE: 0.14444747849721615\n",
      "epoch: 147\tMAE: 0.14443078585559865\n",
      "epoch: 148\tMAE: 0.14441428809944884\n",
      "epoch: 149\tMAE: 0.14439798164854062\n",
      "epoch: 150\tMAE: 0.14438186301721584\n",
      "epoch: 151\tMAE: 0.14436592881112179\n",
      "epoch: 152\tMAE: 0.1443501757240875\n",
      "epoch: 153\tMAE: 0.14433460053513086\n",
      "epoch: 154\tMAE: 0.14431920010559418\n",
      "epoch: 155\tMAE: 0.1443039713763953\n",
      "epoch: 156\tMAE: 0.14428891136539468\n",
      "epoch: 157\tMAE: 0.14427401716486854\n",
      "epoch: 158\tMAE: 0.14425928593908566\n",
      "epoch: 159\tMAE: 0.14424471492197968\n",
      "epoch: 160\tMAE: 0.14423030141491608\n",
      "epoch: 161\tMAE: 0.14421604278454653\n",
      "epoch: 162\tMAE: 0.14420193646074578\n",
      "epoch: 163\tMAE: 0.1441879799346319\n",
      "epoch: 164\tMAE: 0.14417417075665945\n",
      "epoch: 165\tMAE: 0.14416050653478812\n",
      "epoch: 166\tMAE: 0.14414698493271916\n",
      "epoch: 167\tMAE: 0.14413360366820013\n",
      "epoch: 168\tMAE: 0.1441203605113904\n",
      "epoch: 169\tMAE: 0.14410725328328883\n",
      "epoch: 170\tMAE: 0.14409427985422027\n",
      "epoch: 171\tMAE: 0.14408143814237476\n",
      "epoch: 172\tMAE: 0.14406872611240176\n",
      "epoch: 173\tMAE: 0.14405614177405482\n",
      "epoch: 174\tMAE: 0.1440436831808838\n",
      "epoch: 175\tMAE: 0.14403134842897405\n",
      "epoch: 176\tMAE: 0.14401913565573038\n",
      "epoch: 177\tMAE: 0.14400704303870338\n",
      "epoch: 178\tMAE: 0.14399506879445637\n",
      "epoch: 179\tMAE: 0.14398321117747076\n",
      "epoch: 180\tMAE: 0.14397146847909262\n",
      "epoch: 181\tMAE: 0.14395983902650902\n",
      "epoch: 182\tMAE: 0.14394832118176545\n",
      "epoch: 183\tMAE: 0.14393691334081196\n",
      "epoch: 184\tMAE: 0.1439256139325829\n",
      "epoch: 185\tMAE: 0.1439144214181072\n",
      "epoch: 186\tMAE: 0.14390333428964877\n",
      "epoch: 187\tMAE: 0.143892351069873\n",
      "epoch: 188\tMAE: 0.14388147031104284\n",
      "epoch: 189\tMAE: 0.1438706905942401\n",
      "epoch: 190\tMAE: 0.1438600105286103\n",
      "epoch: 191\tMAE: 0.14384942875063533\n",
      "epoch: 192\tMAE: 0.14383894392342636\n",
      "epoch: 193\tMAE: 0.14382855473603856\n",
      "epoch: 194\tMAE: 0.14381825990281247\n",
      "epoch: 195\tMAE: 0.14380805816272857\n",
      "epoch: 196\tMAE: 0.14379794827878872\n",
      "epoch: 197\tMAE: 0.14378792903741244\n",
      "epoch: 198\tMAE: 0.14377799924785326\n",
      "epoch: 199\tMAE: 0.14376815774163473\n",
      "epoch: 200\tMAE: 0.1437584033719995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.        , 5.        , 5.        , 4.5       , 5.        ,\n",
       "        5.        , 3.38076626, 4.5       , 4.5       , 4.5       ],\n",
       "       [4.77815366, 5.        , 4.        , 4.5       , 3.49192348,\n",
       "        3.0804319 , 3.5       , 4.5       , 4.79847004, 4.5       ],\n",
       "       [4.        , 3.5       , 2.40761347, 2.5       , 4.39193926,\n",
       "        4.        , 6.18488494, 3.5       , 4.5       , 2.04593006],\n",
       "       [3.5       , 3.5       , 3.        , 2.64084966, 4.        ,\n",
       "        4.        , 3.5       , 4.        , 3.5       , 2.99901648],\n",
       "       [4.5       , 4.5       , 3.75464533, 4.        , 3.43509021,\n",
       "        3.        , 3.5       , 4.31693774, 4.5       , 4.        ],\n",
       "       [4.84196609, 5.        , 4.58861093, 5.        , 3.        ,\n",
       "        2.64102437, 2.        , 5.        , 4.54489243, 5.        ],\n",
       "       [5.        , 4.        , 5.        , 4.        , 5.18460083,\n",
       "        5.        , 4.        , 5.        , 4.71719566, 5.        ],\n",
       "       [5.        , 5.        , 5.        , 3.        , 5.        ,\n",
       "        5.        , 2.        , 4.75705175, 4.        , 5.        ],\n",
       "       [5.        , 4.75108623, 4.50442805, 4.        , 5.        ,\n",
       "        5.        , 4.        , 5.        , 5.        , 4.        ],\n",
       "       [4.93407528, 5.        , 4.07691217, 4.83390534, 3.5       ,\n",
       "        3.        , 3.84261158, 4.79138466, 5.06724424, 4.4005904 ]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mat= train(train_matrix, train_indices, k=3, epoch=200)\n",
    "pred_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 完整流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "def MF(data_path, k:int, epoch:int):\n",
    "    \"\"\"\n",
    "    矩阵分解\n",
    "    :params data_path: 数据路径\n",
    "    :params k: 保留的特征值数量\n",
    "    :params epoch: 迭代次数\n",
    "    \"\"\"\n",
    "    # 数据预处理\n",
    "    data_raw, user, movie = data_preprocess(path=data_path)\n",
    "    # 划分训练集，验证集\n",
    "    train_matrix, valid_matrix, train_indices, valid_indices = spilt_train_valid(data_raw)\n",
    "    # 将训练集的空值部分填入用户评分均值\n",
    "    train_matrix = normalize(train_matrix)\n",
    "    # 训练\n",
    "    predict_matrix = train(train_matrix, train_indices, k=k, epoch=epoch, log=True)\n",
    "\n",
    "    mae = MAE(valid_matrix, predict_matrix, valid_indices)\n",
    "    rmse = RMSE(valid_matrix, predict_matrix, valid_indices)\n",
    "\n",
    "    plt.bar([\"MAE\",\"RMSE\"], [mae, rmse])\n",
    "    plt.title(\"evaluation\")\n",
    "\n",
    "    pd.DataFrame(predict_matrix, index=user, columns=movie).to_csv(\"svd-predict-rating.csv\")\n",
    "    \n",
    "    return predict_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\tMAE: 0.21235349144597607\n",
      "epoch: 2\tMAE: 0.19414459329313868\n",
      "epoch: 3\tMAE: 0.18415855915897764\n",
      "epoch: 4\tMAE: 0.17840898452339005\n",
      "epoch: 5\tMAE: 0.17482802361369537\n",
      "epoch: 6\tMAE: 0.1722039207680848\n",
      "epoch: 7\tMAE: 0.1698983411605974\n",
      "epoch: 8\tMAE: 0.16782354364283003\n",
      "epoch: 9\tMAE: 0.16608963494831241\n",
      "epoch: 10\tMAE: 0.16457445107775695\n",
      "epoch: 11\tMAE: 0.1632955118402983\n",
      "epoch: 12\tMAE: 0.16225733964225345\n",
      "epoch: 13\tMAE: 0.16135774372199943\n",
      "epoch: 14\tMAE: 0.1605325795574629\n",
      "epoch: 15\tMAE: 0.159775344660985\n",
      "epoch: 16\tMAE: 0.15907947062840405\n",
      "epoch: 17\tMAE: 0.15843849454106648\n",
      "epoch: 18\tMAE: 0.15784614250873247\n",
      "epoch: 19\tMAE: 0.15729637834898\n",
      "epoch: 20\tMAE: 0.1567834394047729\n",
      "epoch: 21\tMAE: 0.15630186807906438\n",
      "epoch: 22\tMAE: 0.1558465422793059\n",
      "epoch: 23\tMAE: 0.15541270586574293\n",
      "epoch: 24\tMAE: 0.15499599923952867\n",
      "epoch: 25\tMAE: 0.15459248953538962\n",
      "epoch: 26\tMAE: 0.15419869924196464\n",
      "epoch: 27\tMAE: 0.15381163146091145\n",
      "epoch: 28\tMAE: 0.15342878953021744\n",
      "epoch: 29\tMAE: 0.1530481884937706\n",
      "epoch: 30\tMAE: 0.15266835599106565\n",
      "epoch: 31\tMAE: 0.15233791386785317\n",
      "epoch: 32\tMAE: 0.15204284606041152\n",
      "epoch: 33\tMAE: 0.15174736179535875\n",
      "epoch: 34\tMAE: 0.15153339498012192\n",
      "epoch: 35\tMAE: 0.15135810369608751\n",
      "epoch: 36\tMAE: 0.15119828673678573\n",
      "epoch: 37\tMAE: 0.1510373200985102\n",
      "epoch: 38\tMAE: 0.1508947898726488\n",
      "epoch: 39\tMAE: 0.1507482112431382\n",
      "epoch: 40\tMAE: 0.1505979860103304\n",
      "epoch: 41\tMAE: 0.15044477146910284\n",
      "epoch: 42\tMAE: 0.15031331495277836\n",
      "epoch: 43\tMAE: 0.1501786609402597\n",
      "epoch: 44\tMAE: 0.15004153028805833\n",
      "epoch: 45\tMAE: 0.14990264254068478\n",
      "epoch: 46\tMAE: 0.14976269425782465\n",
      "epoch: 47\tMAE: 0.14962234247926876\n",
      "epoch: 48\tMAE: 0.14948219293125106\n",
      "epoch: 49\tMAE: 0.14934279241882129\n",
      "epoch: 50\tMAE: 0.14920462476636548\n",
      "epoch: 51\tMAE: 0.1490681096478295\n",
      "epoch: 52\tMAE: 0.1489336036734762\n",
      "epoch: 53\tMAE: 0.14880140315578902\n",
      "epoch: 54\tMAE: 0.1486717480503174\n",
      "epoch: 55\tMAE: 0.14854482664751378\n",
      "epoch: 56\tMAE: 0.1484207806714944\n",
      "epoch: 57\tMAE: 0.14829971051619298\n",
      "epoch: 58\tMAE: 0.14818168041571872\n",
      "epoch: 59\tMAE: 0.14806672340253213\n",
      "epoch: 60\tMAE: 0.14795484595414432\n",
      "epoch: 61\tMAE: 0.1478460322668764\n",
      "epoch: 62\tMAE: 0.14774087205708453\n",
      "epoch: 63\tMAE: 0.1476434230284803\n",
      "epoch: 64\tMAE: 0.1475484572531609\n",
      "epoch: 65\tMAE: 0.14745593212541364\n",
      "epoch: 66\tMAE: 0.14736579733624922\n",
      "epoch: 67\tMAE: 0.14727799668072034\n",
      "epoch: 68\tMAE: 0.14719246959432272\n",
      "epoch: 69\tMAE: 0.14710915244858194\n",
      "epoch: 70\tMAE: 0.1470279796345866\n",
      "epoch: 71\tMAE: 0.14694888446131704\n",
      "epoch: 72\tMAE: 0.14687179989343002\n",
      "epoch: 73\tMAE: 0.14679665915081916\n",
      "epoch: 74\tMAE: 0.14672339618993382\n",
      "epoch: 75\tMAE: 0.14665194608456958\n",
      "epoch: 76\tMAE: 0.14658224532169675\n",
      "epoch: 77\tMAE: 0.1465142320259228\n",
      "epoch: 78\tMAE: 0.14644784612437067\n",
      "epoch: 79\tMAE: 0.1463830294621282\n",
      "epoch: 80\tMAE: 0.14632198377392697\n",
      "epoch: 81\tMAE: 0.14627301681625202\n",
      "epoch: 82\tMAE: 0.1462251818964359\n",
      "epoch: 83\tMAE: 0.14617843932259633\n",
      "epoch: 84\tMAE: 0.14613275074960033\n",
      "epoch: 85\tMAE: 0.14608807920716685\n",
      "epoch: 86\tMAE: 0.14604438910972145\n",
      "epoch: 87\tMAE: 0.14600164625162818\n",
      "epoch: 88\tMAE: 0.1459598177908565\n",
      "epoch: 89\tMAE: 0.14591887222363104\n",
      "epoch: 90\tMAE: 0.14587877935218566\n",
      "epoch: 91\tMAE: 0.14583951024737493\n",
      "epoch: 92\tMAE: 0.14580103720758486\n",
      "epoch: 93\tMAE: 0.14576333371512687\n",
      "epoch: 94\tMAE: 0.1457263743910727\n",
      "epoch: 95\tMAE: 0.14569013494930655\n",
      "epoch: 96\tMAE: 0.14565459215041973\n",
      "epoch: 97\tMAE: 0.14561972375593246\n",
      "epoch: 98\tMAE: 0.1455855084832355\n",
      "epoch: 99\tMAE: 0.14555192596153765\n",
      "epoch: 100\tMAE: 0.14551895668905312\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_mat = MF('svd-raw-data.csv', k=3, epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行时间：1.0842437744140625s\n"
     ]
    }
   ],
   "source": [
    "print(f\"运行时间：{time.time() - start_time}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_matrix = np.array([[4,3,0,0,0,4],\n",
    "#                          [4,1,3,0,4,4],\n",
    "#                          [0,1,3,4,2,5],\n",
    "#                          [3,0,3,0,4,4],\n",
    "#                          [3,4,3,0,3,3],\n",
    "#                          [4,0,3,5,3,4]])\n",
    "# train_indices = np.where(train_matrix != 0)\n",
    "# valid_indices = np.where(train_matrix == 0)\n",
    "# train_matrix = normalize(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = SVD(train_matrix, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE(train_matrix, pred, train_indices), RMSE(train_matrix, pred, train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = train(train_matrix, train_indices, k=3, epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
